link,location,title,company,salary,desc,keywords,similarity_cosine
https://www.indeed.ca/rc/clk?jk=2b943a97c4257feb&fccid=10b5c722d846df43&vjs=3,"Vancouver,BC",Data Scientist - NuData Security,MasterCard,,"Mastercard's Enterprise Security Solutions organization develops and delivers world-class security products and services for customers across the globe. NuData Security predicts fraudulent transactions by identifying good users from bad, based on their online behavior. By analyzing over 38 billion behaviors annually, NuData harnesses the power of behavioral and biometric analysis to empower its clients to predict fraud and verify the user behind the device. This allows clients to predict fraud before a critical decision, reduce customer insult, and investigate bad actors efficiently.

Role
We are looking for a Data Scientist to join our team in our Vancouver office. This is a key role within the team responsible for researching and developing NuData’s security solutions and you’ll have exciting responsibilities, including:

Designing, building and deploying machine learning models in collaboration with an agile, high-functioning Data Science team.
Identifying new opportunities in data collection, feature creation, feature selection, model tuning and evaluation workflow, then taking those ideas from first concepts to live product integrations.
Implementing effective monitoring and benchmarking for models and targeting improvements via thorough analysis of massively parallel model deployments.
Partner with NuData’s Data Science and Data Engineering teams to identify and drive opportunities, pioneering the algorithms and systems that power our commercial products.




All About You
Ideally, you’re:
Experienced in deploying machine learning models to solve real problems and generate competitive edge. You understand good deployment practices and have experience with processes like containerization. Ideally you have successfully developed, deployed, monitored and improved on production models in business contexts.
A capable coder, able to write well-abstracted, reusable, resilient code in Python, Java or Scala. You’re experienced with web services (e.g. EC2, EMR, ECR, Lambda, Sagemaker, Glue, Kinesis, Redshift), and machine learning tools (e.g. Tensorflow, Keras, MXNet, Gluon).
Experienced working with cloud environments. You understand the benefits of cloud infrastructure and know how to design an effective machine learning pipeline in AWS or Google Cloud to automate and scale out machine learning workflows. You have the vision to see what the next generation ML infrastructure looks like.
Familiar with statistical and machine learning concepts. You’re able to inform design discussions and support your teammates via collaborative design, review and recommendations.
A capable communicator in visual and verbal channels, able to explain decisions or concepts to colleagues and provide clear, actionable recommendations.

It also helps if you are:
Collaborative. We do our best work as a team, which means sharing, being open to support and giving constructive input.
Evidence-based. We work to eliminate assumptions and test our hypotheses, and we value rigor.
Responsible. We offer the opportunity to drive major projects that protect consumers every day, internationally. We are looking for colleagues who care about that.
Motivated. We’re a team of data scientists with personal and collaborative side projects, and we’re looking for someone who shares our enthusiasm.


Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.

If you require accommodations or assistance to complete the online application process, please contact reasonable.accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.","['keras', 'aws', 'java', 'agile', 'power', 'google', 'tensorflow', 'mxnet', 'scala', 'python']",0.5590169943749475
https://www.indeed.ca/rc/clk?jk=9c977136e5f64e8a&fccid=be3dbfb6ca2ac450&vjs=3,"Toronto,ON",Data Scientist,Canvass Analytics Inc.,,"Job Description
As a Data Scientist at Canvass Analytics, you will be using artificial intelligence to solve some of the most complex processes in the Industrial sector. In this role, you will contribute to the development and deployment of modern artificial intelligence, machine learning, deep learning, operational research, semantic analysis, and statistical methods for finding structure in large data sets. The Data Scientist will regularly work with the Product team in order to disseminate knowledge and skills specific to the operational requirements, collection and handling of Industrial operational data.
Key Attributes of the Data Scientist Role:
A strong background in statistics, advanced machine learning technologies and deep learning
Demonstrated success in solving complex problems using AI, preferably in Industrial environments
Experience in dealing with variously-structured, massive datasets
Competence with rapid prototyping of data analysis procedures and modeling, as well as with iterative development of complex production-bound models
Ability to take large-scale perspective over their work in order to evaluate delivered value
Out-of-the-box thinker
Familiarity with at least one foundational programming language: C++, Python, or Java
Responsibilities:
Develop and enhance the algorithms and technology that power the Canvass AI Platform
Identify, research and realize key machine learning technical capabilities in the industry
Lead, design, and build mid- to high complexity machine learning systems
Clearly articulate point-of-view, taking into account the perspective of all related parties in the machine learning technology solution space
Adapt communication techniques for audiences at multiple internal/external levels to achieve clear representation of complex concepts and business use cases
Foster effective learning team environment in machine learning space
Develop customer facing reports showing the results and analysis through the Canvass Analytics platform
Required Technical & Professional Skills:
Minimum 4 years professional experience in machine learning
Self-reliant; able to work independently and accept responsibility for projects
Willingness to learn and experiment and a passion for technology
Excellent communications skills to communicate high level concepts to our development and product teams as well as our customers
Readiness to travel 20% annually","['c++', 'java', 'power', 'python']",0.5303300858899106
https://www.indeed.ca/rc/clk?jk=d495a7e3b7c8531d&fccid=4271edc9c2f82254&vjs=3,"Montréal,QC",Data Engineer,Sun Life Financial,,"At Sun Life, we work together, share common values and encourage growth and achievement. We offer many career paths that attract a wide variety of talent and skills. Follow a path that lets your talents shine.



Job Description:

We are currently looking for a Data Engineer with a passion for turning disparate streams of data into organized and actionable analytics services and insights. As a Data Engineer on the Data Engineering and Operations team, you will be joining a group of hardworking and savvy innovators who has made it their mission to find new ways to glean value out of rapidly increasing volumes of operational data in Canadian Operations.

Role Summary:

Working within a diverse and motivated team of analytics professionals, the Data Engineer will lead the development of efficient data capture and transformation processes and complex data models that form the core of a new generation of analytics services and self-serve solutions for our customers in Canadian Operations.

Main Responsibilities:
Lead development of new batch/low-latency analytical solutions that leverages both traditional and emerging technologies
Design, develop and implement highly scalable data capture and transformation processes
Create effective ETLs/ELTs to move large volumes of data from various operational systems to dimensional data models for analytics consumption
Act as principal designer and reviewer for new data models, make data architectural decision, and provide coaching on data modeling and process design
Expand and grow data existing platform capabilities to solve new data problems and challenges
Ensure all automated processes preserve data integrity by managing the alignment of data availability and integration processes
Support quantitative analysts and data scientists with data discovery and rapid assembly of large data sets from disparate sources
Identify opportunities for new data acquisition and new uses for existing data resources
Research and make recommendations for new data management technologies and software engineering practices. Collaborate on decisions around the use of new tools and practices
Perform quality assurance and testing according to risk assessment guidelines to minimize operational, reputation, and legal risk
Define data retention policy, establish data governance best practice, and create automated anomaly detection services
Document and update business continuity and disaster recovery procedures
Engage in ongoing collaboration with data architects, modellers and other members to achieve common goals
Provide guidance to development teams regarding best practices and design patterns for analytics solutions. Coach and provide guidance to junior team members
Produce and maintain support documentation for ongoing operations
Act as Tier-2/3 support to troubleshoot and resolve technical issues with production data models and services

Preferred skills:
University degree in Computer Science, Software Engineering, or equivalent
Experience with hybrid data environments that leverage both distributed and relational database technologies to support analytics services
Solid understanding of data warehousing principles, architecture and its implementation in complex environments
Hands-on experience with development of ELT/ETL processes in traditional and distributed environments
Experience as designer of complex Dimensional data models for analytics services
Experience with development for Microsoft SQL Server Analysis Services or equivalent technologies
Experience with various testing methodologies and user acceptance testing
Solid skills in SQL, Python, C++, Java and other languages used in data manipulation
Experience with Hadoop and Big Data technology
Experience with processing large datasets from multiple sources
Ability to operate effectively and independently in a dynamic, fluid environment
Strong verbal and written communications skills with experience in relating complex concepts to non-technical users
Demonstrated ability to exchange ideas and convey complex information clearly and concisely
Proven ability to lead and drive projects and assignments to completion

Assets:
Experience with optimization and tuning of large data extracts for Tableau
Familiarity with Agile development practices
Understanding of ITIL processes Incident/Change/Release management methodologies
Knowledge of Insurance or Financial Services industry

Diversity and inclusion have always been at the core of our values at Sun Life. A diverse workforce with wide perspectives and creative ideas benefits our clients, the communities where we operate and all of us as colleagues. We welcome applications from qualified individuals from all backgrounds.

Persons with disabilities who need accommodation in the application process, or those needing job postings in an alternative format, may e-mail a request to thebrightside@sunlife.com

We thank all applicants for showing an interest in this position. Only those selected for an interview will be contacted.



Job Category:
Advanced Analytics


Posting End Date:
25/10/2018","['hadoop', 'etl', 'tableau', 'c++', 'java', 'agile', 'sql', 'python']",0.5
https://www.indeed.ca/pagead/clk?mo=r&ad=-6NYlbfkN0AnvNz4Za0rua_1kbpWr6zQfHkozpsvf0dmR4SuLanQW3roou42yRCgAGet45vB_UkWo1ih9E2KjaZbbNckmZMvDqDFL3G8pmv_sbYGEE-Q2urNkaOji2ehMYoGFNuByCR-LYssHgHEbCYgmK2gzsqs_mIzfhhIpPQZ3f7POSuD8tIn3Knzi3G5EMI8EtCJ4k9NUV42A_xA64rGZlA8iS_BuCdghLrRSlDteVfPOFdf2BV-S_y5Lz5hyp-IDlMZaZO9YapTno0JZn5XWIF3oWFLQZkFMymO_Bb_9TQCUahDnCE3hAxOLMVBhiD0f5JwTzDcuipjx8VZSKuPXL-oJJd0rmouI930RtCCMJG6pOFjPL8OvIjhoIqAEPcsV1r3tNgrSM_WRNwp2XhLcxZ-xBetkPsRjvnDOTefvoC_3X7hwNS9UI5bQJU16HgcTtNouvSYjB8Emx18-2kY7auMI3Gni4ZkSyZgUMHhT9toTg-CW9HU5h6QVcUyY24yq4xRdPuCYwXjTKQQJQ==&vjs=3&p=5&sk=&fvj=1,"Montréal,QC",Business Systems Analyst,Intellistaff,,"Our client is seeking an experienced Bilingual (English and French - you don't necessarily have to be 100% fluent in both languages but you can function professionally in both languages) Business Systems Analyst to work on their client's site on Nun's Island in Verdun. We have placed several individuals with this organization and they very much enjoy working here.
Your skills and experience include the typical BA/BSA activities including gathering requirements, creating BRD and SRS documents, working with the user community and writing user stories. You are perhaps somewhat more technical than the average BA in that you have some experience developing prototypes and POCs. In addition, you have experience with process and data modeling using tools such as Visio.
You bring at least 8 years of progressive BA/BSA experience to the table, with at least 4-5 years of this working on full life cycle software development projects. The client will also consider you if you started your career as a developer or DBA and more recently evolved into BA or Data Analyst roles. You have experience with both Waterfall and Iterative (ie: Agile, Scrum, etc.) approaches. Finally, it would be a strong asset if you have some experience writing and validating test cases, as well as having some experience with functional testing and UAT.
If this sounds like you and you want to work with a company that truly supports their employees, drop me a line. Please note that this is a confidential search and I can't divulge the identity the client or their exact location via email, but I can fully disclose their identity once we have a quick phone conversation. I would need about 5-10 minutes of your time.
Thanks!
**** PLEASE NOTE - This is a full time position
Job Type: Full-time
Experience:
progressive BA/BSA: 8 years (Preferred)","['agile', 'scrum']",0.5
https://www.indeed.ca/pagead/clk?mo=r&ad=-6NYlbfkN0DfaJzxeKsHg3yNa09Lu8cQQduvjegwzxl5yjE4sdO8aCQ7r433WSCgz7HcYFllrICUutaiYZ3SywZPE6JNXcysT7G1p3sESm5Ew2MJJ_yjBhQH-5XCgk4BN-i8NEEjgeaCDFlZ8KG_bDlKLDPngTr06lU2YfRyF8Zx_JQNYV-F50oihPReKCVJmsJTqZlF_ktUoZ-HFD4-GZ1Siqq4H-HTy5rdZE6_k0C6fHhFtfn09mCL_1F3nwh--NKU2LKo0l7IJefV0q1fIPF1cA6QldA_-oWRn31ij-Lj3ulDPwrbIeelz38Lr8r8xGCJs-K9qBi9tKs_ayb78YmNrdMDK8FWVGAZsgw3ntEUgILSgMJ9k5QKEcNLRYZA_oIjQdXw2D1jIdZxM65ShWi3KMnFMsgJm-XOPlfRbXOWV4smO302WQWrk2jr7EV_nZXY82n7CHCVuDmxem5uMpYnSLMVfmFArK47iZfuPsWMWpHPux3199l2GtCSwBeHZGI_PyQPRXZd-udMfu9YUdAM_Khq7_OWATW9HcwCDMYRn1T1Q8_2jfwbith7dbB58F1Rcp5MMLG7XbnL2r9GCPWEVFJKQ6n1PkHE3cmrY0McgN2OZpGCxQ==&vjs=3&p=2&sk=&fvj=0,"Montréal,QC",Data Engineer,Sun Life Financial,,"At Sun Life, we work together, share common values and encourage growth and achievement. We offer many career paths that attract a wide variety of talent and skills. Follow a path that lets your talents shine.



Job Description:

We are currently looking for a Data Engineer with a passion for turning disparate streams of data into organized and actionable analytics services and insights. As a Data Engineer on the Data Engineering and Operations team, you will be joining a group of hardworking and savvy innovators who has made it their mission to find new ways to glean value out of rapidly increasing volumes of operational data in Canadian Operations.

Role Summary:

Working within a diverse and motivated team of analytics professionals, the Data Engineer will lead the development of efficient data capture and transformation processes and complex data models that form the core of a new generation of analytics services and self-serve solutions for our customers in Canadian Operations.

Main Responsibilities:
Lead development of new batch/low-latency analytical solutions that leverages both traditional and emerging technologies
Design, develop and implement highly scalable data capture and transformation processes
Create effective ETLs/ELTs to move large volumes of data from various operational systems to dimensional data models for analytics consumption
Act as principal designer and reviewer for new data models, make data architectural decision, and provide coaching on data modeling and process design
Expand and grow data existing platform capabilities to solve new data problems and challenges
Ensure all automated processes preserve data integrity by managing the alignment of data availability and integration processes
Support quantitative analysts and data scientists with data discovery and rapid assembly of large data sets from disparate sources
Identify opportunities for new data acquisition and new uses for existing data resources
Research and make recommendations for new data management technologies and software engineering practices. Collaborate on decisions around the use of new tools and practices
Perform quality assurance and testing according to risk assessment guidelines to minimize operational, reputation, and legal risk
Define data retention policy, establish data governance best practice, and create automated anomaly detection services
Document and update business continuity and disaster recovery procedures
Engage in ongoing collaboration with data architects, modellers and other members to achieve common goals
Provide guidance to development teams regarding best practices and design patterns for analytics solutions. Coach and provide guidance to junior team members
Produce and maintain support documentation for ongoing operations
Act as Tier-2/3 support to troubleshoot and resolve technical issues with production data models and services

Preferred skills:
University degree in Computer Science, Software Engineering, or equivalent
Experience with hybrid data environments that leverage both distributed and relational database technologies to support analytics services
Solid understanding of data warehousing principles, architecture and its implementation in complex environments
Hands-on experience with development of ELT/ETL processes in traditional and distributed environments
Experience as designer of complex Dimensional data models for analytics services
Experience with development for Microsoft SQL Server Analysis Services or equivalent technologies
Experience with various testing methodologies and user acceptance testing
Solid skills in SQL, Python, C++, Java and other languages used in data manipulation
Experience with Hadoop and Big Data technology
Experience with processing large datasets from multiple sources
Ability to operate effectively and independently in a dynamic, fluid environment
Strong verbal and written communications skills with experience in relating complex concepts to non-technical users
Demonstrated ability to exchange ideas and convey complex information clearly and concisely
Proven ability to lead and drive projects and assignments to completion

Assets:
Experience with optimization and tuning of large data extracts for Tableau
Familiarity with Agile development practices
Understanding of ITIL processes Incident/Change/Release management methodologies
Knowledge of Insurance or Financial Services industry

Diversity and inclusion have always been at the core of our values at Sun Life. A diverse workforce with wide perspectives and creative ideas benefits our clients, the communities where we operate and all of us as colleagues. We welcome applications from qualified individuals from all backgrounds.

Persons with disabilities who need accommodation in the application process, or those needing job postings in an alternative format, may e-mail a request to thebrightside@sunlife.com

We thank all applicants for showing an interest in this position. Only those selected for an interview will be contacted.



Job Category:
Advanced Analytics


Posting End Date:
25/10/2018","['hadoop', 'etl', 'tableau', 'c++', 'java', 'agile', 'sql', 'python']",0.5
